Show configuration
adam:
  beta1: 0.9
  beta2: 0.999
cuhk03:
  classic_split: False
  labeled_images: True
  use_metric_cuhk03: False
data:
  combineall: False
  height: 256
  norm_mean: [0.485, 0.456, 0.406]
  norm_std: [0.229, 0.224, 0.225]
  root: /home/s2019020843/changeeeee/data/
  save_dir: log
  sources: ['market1501']
  split_id: 0
  targets: ['market1501']
  transforms: ['random_flip', 'random_erase']
  type: image
  width: 128
  workers: 4
loss:
  name: triplet
  softmax:
    label_smooth: True
  triplet:
    margin: 0.1
    weight_t: 1.0
    weight_x: 1.0
market1501:
  use_500k_distractors: False
model:
  load_weights: 
  name: plr_osnet
  pretrained: True
  resume: 
rmsprop:
  alpha: 0.99
sampler:
  num_instances: 4
  train_sampler: RandomIdentitySampler
sgd:
  dampening: 0.0
  momentum: 0.9
  nesterov: False
test:
  batch_size: 300
  dist_metric: euclidean
  eval_freq: 10
  evaluate: False
  normalize_feature: False
  ranks: [1, 5, 10, 20]
  rerank: False
  start_eval: 0
  visactmap: False
  visrank: False
  visrank_topk: 10
train:
  base_lr_mult: 0.1
  batch_size: 64
  fixbase_epoch: 0
  gamma: 0.1
  lr: 3.5e-05
  lr_scheduler: warmup
  max_epoch: 150
  multiplier: 10
  new_layers: ['classifier']
  open_layers: ['classifier']
  optim: adam
  print_freq: 20
  seed: 1
  staged_lr: False
  start_epoch: 0
  stepsize: [60, 90]
  total_epoch: 39
  weight_decay: 0.0005
use_gpu: True
video:
  pooling_method: avg
  sample_method: evenly
  seq_len: 15

Collecting env info ...
** System info **
PyTorch version: 1.5.1
Is debug build: No
CUDA used to build PyTorch: 10.2

OS: CentOS Linux 7 (Core)
GCC version: (GCC) 4.8.5 20150623 (Red Hat 4.8.5-39)
CMake version: Could not collect

Python version: 3.7
Is CUDA available: Yes
CUDA runtime version: 10.2.89
GPU models and configuration: 
GPU 0: GeForce RTX 2080 Ti
GPU 1: GeForce RTX 2080 Ti
GPU 2: GeForce RTX 2080 Ti
GPU 3: GeForce RTX 2080 Ti

Nvidia driver version: 440.82
cuDNN version: Could not collect

Versions of relevant libraries:
[pip3] numpy==1.19.0
[pip3] torch==1.5.1
[pip3] torchvision==0.6.1
[conda] torch                     1.5.1                     <pip>
[conda] torchvision               0.6.1                     <pip>
        Pillow (7.1.2)

Building train transforms ...
+ resize to 256x128
+ random flip
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
+ random erase
Building test transforms ...
+ resize to 256x128
+ to torch tensor of range [0, 1]
+ normalization (mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
=> Loading train (source) dataset
=> Loaded Market1501
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   751 |    12936 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------
=> Loading test (target) dataset
=> Loaded Market1501
  ----------------------------------------
  subset   | # ids | # images | # cameras
  ----------------------------------------
  train    |   751 |    12936 |         6
  query    |   750 |     3368 |         6
  gallery  |   751 |    15913 |         6
  ----------------------------------------


  **************** Summary ****************
  train            : ['market1501']
  # train datasets : 1
  # train ids      : 751
  # train images   : 12936
  # train cameras  : 6
  test             : ['market1501']
  *****************************************


Building model: plr_osnet
Successfully loaded imagenet pretrained weights from "/home/s2019020843/.cache/torch/checkpoints/osnet_x1_0_imagenet.pth"
Model complexity: params=2,533,584 flops=1,071,153,040
Model structure: PLR_OSNet(
  (layer0): Sequential(
    (0): ConvLayer(
      (conv): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)
      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      (relu): ReLU(inplace=True)
    )
    (1): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)
  )
  (layer1): Sequential(
    (0): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Conv1x1Linear(
        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
        (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=64, bias=False)
          (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(64, 4, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(4, 64, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): Conv1x1(
        (conv): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
  )
  (layer2): Sequential(
    (0): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(256, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Conv1x1Linear(
        (conv): Conv2d(256, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
        (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(96, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(96, 96, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=96, bias=False)
          (bn): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(96, 6, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(6, 96, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(96, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (2): Sequential(
      (0): Conv1x1(
        (conv): Conv2d(384, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (1): AvgPool2d(kernel_size=2, stride=2, padding=0)
    )
  )
  (layer3): Sequential(
    (0): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(384, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
      (downsample): Conv1x1Linear(
        (conv): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
    (1): OSBlock(
      (conv1): Conv1x1(
        (conv): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2a): LightConv3x3(
        (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
        (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
        (relu): ReLU(inplace=True)
      )
      (conv2b): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2c): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (conv2d): Sequential(
        (0): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (1): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (2): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
        (3): LightConv3x3(
          (conv1): Conv2d(128, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)
          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128, bias=False)
          (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
          (relu): ReLU(inplace=True)
        )
      )
      (gate): ChannelGate(
        (global_avgpool): AdaptiveAvgPool2d(output_size=1)
        (fc1): Conv2d(128, 8, kernel_size=(1, 1), stride=(1, 1))
        (relu): ReLU(inplace=True)
        (fc2): Conv2d(8, 128, kernel_size=(1, 1), stride=(1, 1))
        (gate_activation): Sigmoid()
      )
      (conv3): Conv1x1Linear(
        (conv): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
        (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
      )
    )
  )
  (layer4): Conv1x1(
    (conv): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
    (bn): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
    (relu): ReLU(inplace=True)
  )
  (conv10): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (conv20): Conv2d(384, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)
  (global_avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  (global_maxpool): AdaptiveMaxPool2d(output_size=(1, 1))
  (fc1): Linear(in_features=512, out_features=512, bias=True)
  (bn1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (bn2): BatchNorm1d(6144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
  (classifier1): Linear(in_features=512, out_features=751, bias=True)
  (classifier2): Linear(in_features=6144, out_features=751, bias=True)
)
Building triplet-engine for image-reid
=> Start training
Epoch: [1/150][20/185]	Time 0.428 (0.488)	Data 0.000 (0.029)	Loss_t 0.5794 (0.6606)	Loss_x 6.8249 (6.7491)	Acc 0.00 (0.08)	Lr 0.000035	eta 3:45:28
Epoch: [1/150][40/185]	Time 0.422 (0.454)	Data 0.000 (0.014)	Loss_t 0.5527 (0.6030)	Loss_x 6.6783 (6.7299)	Acc 1.56 (0.27)	Lr 0.000035	eta 3:29:27
Epoch: [1/150][60/185]	Time 0.423 (0.439)	Data 0.000 (0.010)	Loss_t 0.4934 (0.5656)	Loss_x 6.5964 (6.7010)	Acc 1.56 (0.26)	Lr 0.000035	eta 3:22:27
Epoch: [1/150][80/185]	Time 0.386 (0.426)	Data 0.000 (0.007)	Loss_t 0.4567 (0.5419)	Loss_x 6.6152 (6.6797)	Acc 0.00 (0.21)	Lr 0.000035	eta 3:16:29
Epoch: [1/150][100/185]	Time 0.420 (0.423)	Data 0.000 (0.006)	Loss_t 0.4019 (0.5215)	Loss_x 6.5150 (6.6568)	Acc 0.00 (0.22)	Lr 0.000035	eta 3:14:57
Epoch: [1/150][120/185]	Time 0.399 (0.422)	Data 0.000 (0.005)	Loss_t 0.4171 (0.5053)	Loss_x 6.4562 (6.6322)	Acc 0.00 (0.20)	Lr 0.000035	eta 3:14:21
Epoch: [1/150][140/185]	Time 0.427 (0.423)	Data 0.000 (0.004)	Loss_t 0.3942 (0.4919)	Loss_x 6.4284 (6.6068)	Acc 0.00 (0.18)	Lr 0.000035	eta 3:14:29
Epoch: [1/150][160/185]	Time 0.445 (0.423)	Data 0.000 (0.004)	Loss_t 0.3730 (0.4802)	Loss_x 6.3655 (6.5765)	Acc 3.12 (0.22)	Lr 0.000035	eta 3:14:23
Epoch: [1/150][180/185]	Time 0.437 (0.424)	Data 0.000 (0.003)	Loss_t 0.3582 (0.4683)	Loss_x 6.1212 (6.5383)	Acc 1.56 (0.27)	Lr 0.000035	eta 3:14:44
Epoch: [2/150][20/185]	Time 0.437 (0.465)	Data 0.000 (0.028)	Loss_t 0.3174 (0.3478)	Loss_x 6.1341 (6.1761)	Acc 1.56 (0.39)	Lr 0.000043	eta 3:33:29
Epoch: [2/150][40/185]	Time 0.434 (0.451)	Data 0.000 (0.014)	Loss_t 0.3299 (0.3416)	Loss_x 6.0791 (6.1385)	Acc 0.00 (0.94)	Lr 0.000043	eta 3:26:47
Epoch: [2/150][60/185]	Time 0.442 (0.445)	Data 0.000 (0.009)	Loss_t 0.3259 (0.3378)	Loss_x 6.0762 (6.1268)	Acc 0.00 (0.89)	Lr 0.000043	eta 3:24:12
Epoch: [2/150][80/185]	Time 0.436 (0.443)	Data 0.000 (0.007)	Loss_t 0.3377 (0.3363)	Loss_x 5.9660 (6.0936)	Acc 4.69 (0.96)	Lr 0.000043	eta 3:23:07
Epoch: [2/150][100/185]	Time 0.431 (0.441)	Data 0.000 (0.006)	Loss_t 0.2946 (0.3332)	Loss_x 5.8592 (6.0596)	Acc 1.56 (1.03)	Lr 0.000043	eta 3:22:02
Epoch: [2/150][120/185]	Time 0.434 (0.440)	Data 0.000 (0.005)	Loss_t 0.3120 (0.3310)	Loss_x 5.9277 (6.0261)	Acc 1.56 (1.25)	Lr 0.000043	eta 3:21:27
Epoch: [2/150][140/185]	Time 0.440 (0.440)	Data 0.000 (0.004)	Loss_t 0.3025 (0.3283)	Loss_x 5.6324 (5.9831)	Acc 1.56 (1.47)	Lr 0.000043	eta 3:21:10
Epoch: [2/150][160/185]	Time 0.408 (0.430)	Data 0.000 (0.004)	Loss_t 0.3289 (0.3254)	Loss_x 5.5599 (5.9289)	Acc 3.12 (1.75)	Lr 0.000043	eta 3:16:25
Epoch: [2/150][180/185]	Time 0.427 (0.428)	Data 0.000 (0.003)	Loss_t 0.2756 (0.3213)	Loss_x 4.8391 (5.8488)	Acc 20.31 (3.02)	Lr 0.000043	eta 3:15:08
Epoch: [3/150][20/185]	Time 0.411 (0.447)	Data 0.000 (0.024)	Loss_t 0.2825 (0.2741)	Loss_x 5.7270 (5.4984)	Acc 3.12 (5.78)	Lr 0.000051	eta 3:23:53
Epoch: [3/150][40/185]	Time 0.360 (0.421)	Data 0.000 (0.012)	Loss_t 0.2992 (0.2731)	Loss_x 5.3683 (5.4794)	Acc 9.38 (5.04)	Lr 0.000051	eta 3:11:59
Epoch: [3/150][60/185]	Time 0.401 (0.421)	Data 0.000 (0.008)	Loss_t 0.3015 (0.2719)	Loss_x 5.6445 (5.4480)	Acc 0.00 (5.57)	Lr 0.000051	eta 3:11:53
Epoch: [3/150][80/185]	Time 0.404 (0.415)	Data 0.000 (0.006)	Loss_t 0.3271 (0.2724)	Loss_x 5.3036 (5.4198)	Acc 6.25 (5.64)	Lr 0.000051	eta 3:08:44
Epoch: [3/150][100/185]	Time 0.426 (0.416)	Data 0.000 (0.005)	Loss_t 0.2762 (0.2719)	Loss_x 4.9798 (5.3633)	Acc 7.81 (6.02)	Lr 0.000051	eta 3:09:07
Epoch: [3/150][120/185]	Time 0.422 (0.416)	Data 0.000 (0.004)	Loss_t 0.2187 (0.2662)	Loss_x 4.8140 (5.3040)	Acc 21.88 (6.61)	Lr 0.000051	eta 3:09:07
Epoch: [3/150][140/185]	Time 0.411 (0.415)	Data 0.000 (0.004)	Loss_t 0.2888 (0.2672)	Loss_x 5.0385 (5.2565)	Acc 4.69 (7.30)	Lr 0.000051	eta 3:08:20
Epoch: [3/150][160/185]	Time 0.433 (0.415)	Data 0.000 (0.003)	Loss_t 0.2539 (0.2647)	Loss_x 4.6353 (5.1852)	Acc 29.69 (8.86)	Lr 0.000051	eta 3:08:04
Epoch: [3/150][180/185]	Time 0.372 (0.415)	Data 0.000 (0.003)	Loss_t 0.2413 (0.2634)	Loss_x 4.2701 (5.1027)	Acc 48.44 (10.86)	Lr 0.000051	eta 3:08:15
Epoch: [4/150][20/185]	Time 0.396 (0.444)	Data 0.000 (0.025)	Loss_t 0.2376 (0.2223)	Loss_x 4.6211 (4.8287)	Acc 7.81 (8.75)	Lr 0.000059	eta 3:20:57
Epoch: [4/150][40/185]	Time 0.434 (0.445)	Data 0.000 (0.012)	Loss_t 0.2644 (0.2258)	Loss_x 5.0737 (4.8469)	Acc 7.81 (8.59)	Lr 0.000059	eta 3:21:27
Epoch: [4/150][60/185]	Time 0.436 (0.441)	Data 0.000 (0.008)	Loss_t 0.2542 (0.2278)	Loss_x 4.9504 (4.8052)	Acc 9.38 (8.93)	Lr 0.000059	eta 3:19:33
Epoch: [4/150][80/185]	Time 0.436 (0.443)	Data 0.000 (0.006)	Loss_t 0.1554 (0.2249)	Loss_x 4.3595 (4.7554)	Acc 12.50 (9.51)	Lr 0.000059	eta 3:20:04
Epoch: [4/150][100/185]	Time 0.423 (0.444)	Data 0.000 (0.005)	Loss_t 0.2080 (0.2231)	Loss_x 4.2980 (4.6938)	Acc 17.19 (10.22)	Lr 0.000059	eta 3:20:21
Epoch: [4/150][120/185]	Time 0.436 (0.443)	Data 0.000 (0.004)	Loss_t 0.1801 (0.2225)	Loss_x 4.2803 (4.6460)	Acc 14.06 (10.90)	Lr 0.000059	eta 3:19:50
Epoch: [4/150][140/185]	Time 0.443 (0.442)	Data 0.000 (0.004)	Loss_t 0.1933 (0.2241)	Loss_x 4.2092 (4.5901)	Acc 21.88 (12.69)	Lr 0.000059	eta 3:19:17
Epoch: [4/150][160/185]	Time 0.448 (0.442)	Data 0.000 (0.003)	Loss_t 0.2154 (0.2250)	Loss_x 4.0497 (4.5317)	Acc 26.56 (13.82)	Lr 0.000059	eta 3:19:05
Epoch: [4/150][180/185]	Time 0.436 (0.442)	Data 0.000 (0.003)	Loss_t 0.3011 (0.2242)	Loss_x 3.7469 (4.4478)	Acc 46.88 (16.57)	Lr 0.000059	eta 3:18:55
Epoch: [5/150][20/185]	Time 0.443 (0.464)	Data 0.000 (0.025)	Loss_t 0.2069 (0.2058)	Loss_x 4.2867 (4.3444)	Acc 1.56 (7.66)	Lr 0.000067	eta 3:28:41
Epoch: [5/150][40/185]	Time 0.344 (0.430)	Data 0.000 (0.012)	Loss_t 0.2282 (0.1954)	Loss_x 4.2337 (4.2833)	Acc 20.31 (8.79)	Lr 0.000067	eta 3:13:20
Epoch: [5/150][60/185]	Time 0.359 (0.403)	Data 0.000 (0.008)	Loss_t 0.1302 (0.1941)	Loss_x 4.0487 (4.2435)	Acc 10.94 (10.21)	Lr 0.000067	eta 3:01:06
Epoch: [5/150][80/185]	Time 0.397 (0.408)	Data 0.000 (0.006)	Loss_t 0.1362 (0.1902)	Loss_x 3.8156 (4.1896)	Acc 15.62 (11.60)	Lr 0.000067	eta 3:03:00
Epoch: [5/150][100/185]	Time 0.421 (0.409)	Data 0.000 (0.005)	Loss_t 0.2392 (0.1901)	Loss_x 4.1612 (4.1469)	Acc 6.25 (12.80)	Lr 0.000067	eta 3:03:31
Epoch: [5/150][120/185]	Time 0.474 (0.413)	Data 0.000 (0.004)	Loss_t 0.2163 (0.1898)	Loss_x 3.8484 (4.1026)	Acc 21.88 (14.43)	Lr 0.000067	eta 3:04:56
Epoch: [5/150][140/185]	Time 0.400 (0.417)	Data 0.000 (0.004)	Loss_t 0.1916 (0.1890)	Loss_x 3.7849 (4.0509)	Acc 23.44 (16.29)	Lr 0.000067	eta 3:06:36
Epoch: [5/150][160/185]	Time 0.407 (0.416)	Data 0.000 (0.003)	Loss_t 0.1558 (0.1891)	Loss_x 3.4866 (3.9921)	Acc 34.38 (18.84)	Lr 0.000067	eta 3:06:04
Epoch: [5/150][180/185]	Time 0.437 (0.416)	Data 0.000 (0.003)	Loss_t 0.2251 (0.1890)	Loss_x 3.2159 (3.9147)	Acc 42.19 (22.14)	Lr 0.000067	eta 3:06:10
Epoch: [6/150][20/185]	Time 0.404 (0.456)	Data 0.000 (0.025)	Loss_t 0.1827 (0.1838)	Loss_x 4.1342 (3.9067)	Acc 7.81 (12.19)	Lr 0.000075	eta 3:23:35
Epoch: [6/150][40/185]	Time 0.449 (0.443)	Data 0.000 (0.012)	Loss_t 0.1168 (0.1753)	Loss_x 3.5502 (3.8308)	Acc 26.56 (13.40)	Lr 0.000075	eta 3:17:55
Epoch: [6/150][60/185]	Time 0.437 (0.434)	Data 0.000 (0.008)	Loss_t 0.1376 (0.1707)	Loss_x 3.3452 (3.7795)	Acc 31.25 (14.58)	Lr 0.000075	eta 3:13:35
Epoch: [6/150][80/185]	Time 0.452 (0.429)	Data 0.000 (0.006)	Loss_t 0.0863 (0.1680)	Loss_x 3.6462 (3.7451)	Acc 0.00 (15.45)	Lr 0.000075	eta 3:11:12
Epoch: [6/150][100/185]	Time 0.409 (0.430)	Data 0.000 (0.005)	Loss_t 0.1422 (0.1679)	Loss_x 3.4022 (3.6966)	Acc 21.88 (17.11)	Lr 0.000075	eta 3:11:32
Epoch: [6/150][120/185]	Time 0.407 (0.429)	Data 0.000 (0.004)	Loss_t 0.1754 (0.1658)	Loss_x 3.5841 (3.6588)	Acc 28.12 (18.50)	Lr 0.000075	eta 3:10:44
Epoch: [6/150][140/185]	Time 0.410 (0.426)	Data 0.000 (0.004)	Loss_t 0.1849 (0.1632)	Loss_x 3.3363 (3.6023)	Acc 28.12 (20.65)	Lr 0.000075	eta 3:09:40
Epoch: [6/150][160/185]	Time 0.457 (0.426)	Data 0.000 (0.003)	Loss_t 0.1060 (0.1595)	Loss_x 2.9702 (3.5392)	Acc 51.56 (23.93)	Lr 0.000075	eta 3:09:18
Epoch: [6/150][180/185]	Time 0.398 (0.425)	Data 0.000 (0.003)	Loss_t 0.1599 (0.1598)	Loss_x 2.6493 (3.4714)	Acc 70.31 (27.77)	Lr 0.000075	eta 3:08:35
Epoch: [7/150][20/185]	Time 0.421 (0.457)	Data 0.000 (0.023)	Loss_t 0.0929 (0.1507)	Loss_x 3.2068 (3.4382)	Acc 23.44 (18.98)	Lr 0.000083	eta 3:22:34
Epoch: [7/150][40/185]	Time 0.399 (0.436)	Data 0.000 (0.012)	Loss_t 0.1840 (0.1513)	Loss_x 3.2140 (3.4188)	Acc 39.06 (18.40)	Lr 0.000083	eta 3:13:18
Epoch: [7/150][60/185]	Time 0.470 (0.433)	Data 0.000 (0.008)	Loss_t 0.1284 (0.1483)	Loss_x 3.4772 (3.3948)	Acc 15.62 (19.48)	Lr 0.000083	eta 3:12:00
Epoch: [7/150][80/185]	Time 0.430 (0.434)	Data 0.000 (0.006)	Loss_t 0.1410 (0.1455)	Loss_x 3.1273 (3.3573)	Acc 34.38 (21.09)	Lr 0.000083	eta 3:11:55
Epoch: [7/150][100/185]	Time 0.476 (0.433)	Data 0.000 (0.005)	Loss_t 0.1750 (0.1455)	Loss_x 3.3334 (3.3216)	Acc 31.25 (23.48)	Lr 0.000083	eta 3:11:39
Epoch: [7/150][120/185]	Time 0.455 (0.433)	Data 0.000 (0.004)	Loss_t 0.0731 (0.1434)	Loss_x 2.8804 (3.2832)	Acc 60.94 (25.99)	Lr 0.000083	eta 3:11:11
Epoch: [7/150][140/185]	Time 0.410 (0.429)	Data 0.000 (0.003)	Loss_t 0.0957 (0.1414)	Loss_x 2.6697 (3.2362)	Acc 60.94 (28.23)	Lr 0.000083	eta 3:09:26
Epoch: [7/150][160/185]	Time 0.420 (0.429)	Data 0.000 (0.003)	Loss_t 0.0817 (0.1399)	Loss_x 2.7359 (3.1774)	Acc 51.56 (31.55)	Lr 0.000083	eta 3:09:27
Epoch: [7/150][180/185]	Time 0.426 (0.429)	Data 0.000 (0.003)	Loss_t 0.1067 (0.1396)	Loss_x 2.3797 (3.1061)	Acc 81.25 (35.58)	Lr 0.000083	eta 3:09:21
Epoch: [8/150][20/185]	Time 0.441 (0.451)	Data 0.000 (0.024)	Loss_t 0.1171 (0.1196)	Loss_x 3.0792 (3.1459)	Acc 18.75 (23.98)	Lr 0.000092	eta 3:18:46
Epoch: [8/150][40/185]	Time 0.422 (0.436)	Data 0.000 (0.012)	Loss_t 0.1926 (0.1194)	Loss_x 3.2502 (3.0999)	Acc 10.94 (25.51)	Lr 0.000092	eta 3:11:58
Epoch: [8/150][60/185]	Time 0.438 (0.435)	Data 0.000 (0.008)	Loss_t 0.0676 (0.1182)	Loss_x 3.0698 (3.0491)	Acc 17.19 (28.83)	Lr 0.000092	eta 3:11:25
Epoch: [8/150][80/185]	Time 0.396 (0.433)	Data 0.000 (0.006)	Loss_t 0.1652 (0.1205)	Loss_x 3.1014 (3.0177)	Acc 28.12 (30.43)	Lr 0.000092	eta 3:10:17
Epoch: [8/150][100/185]	Time 0.411 (0.430)	Data 0.000 (0.005)	Loss_t 0.0823 (0.1211)	Loss_x 2.6642 (2.9902)	Acc 42.19 (31.95)	Lr 0.000092	eta 3:08:42
Epoch: [8/150][120/185]	Time 0.388 (0.430)	Data 0.000 (0.004)	Loss_t 0.1440 (0.1193)	Loss_x 2.6519 (2.9542)	Acc 51.56 (34.21)	Lr 0.000092	eta 3:08:52
Epoch: [8/150][140/185]	Time 0.343 (0.418)	Data 0.000 (0.004)	Loss_t 0.1475 (0.1182)	Loss_x 2.6534 (2.8989)	Acc 54.69 (37.35)	Lr 0.000092	eta 3:03:14
Epoch: [8/150][160/185]	Time 0.347 (0.409)	Data 0.000 (0.003)	Loss_t 0.0978 (0.1155)	Loss_x 2.4414 (2.8474)	Acc 62.50 (39.96)	Lr 0.000092	eta 2:59:05
Epoch: [8/150][180/185]	Time 0.423 (0.410)	Data 0.000 (0.003)	Loss_t 0.1141 (0.1139)	Loss_x 2.1987 (2.7781)	Acc 87.50 (43.72)	Lr 0.000092	eta 2:59:30
Epoch: [9/150][20/185]	Time 0.441 (0.449)	Data 0.000 (0.025)	Loss_t 0.0632 (0.0977)	Loss_x 2.4066 (2.7637)	Acc 51.56 (35.62)	Lr 0.000100	eta 3:16:28
Epoch: [9/150][40/185]	Time 0.446 (0.443)	Data 0.000 (0.012)	Loss_t 0.0842 (0.1046)	Loss_x 2.6814 (2.7739)	Acc 28.12 (35.94)	Lr 0.000100	eta 3:13:52
Epoch: [9/150][60/185]	Time 0.351 (0.438)	Data 0.000 (0.008)	Loss_t 0.0512 (0.1026)	Loss_x 2.8801 (2.7707)	Acc 25.00 (36.77)	Lr 0.000100	eta 3:11:21
Epoch: [9/150][80/185]	Time 0.353 (0.415)	Data 0.000 (0.006)	Loss_t 0.1346 (0.1024)	Loss_x 2.5587 (2.7417)	Acc 51.56 (38.96)	Lr 0.000100	eta 3:01:19
Epoch: [9/150][100/185]	Time 0.349 (0.402)	Data 0.000 (0.005)	Loss_t 0.0603 (0.1008)	Loss_x 2.5549 (2.7057)	Acc 56.25 (41.48)	Lr 0.000100	eta 2:55:22
Epoch: [9/150][120/185]	Time 0.351 (0.401)	Data 0.000 (0.004)	Loss_t 0.1239 (0.1016)	Loss_x 2.4721 (2.6728)	Acc 65.62 (43.62)	Lr 0.000100	eta 2:54:41
Epoch: [9/150][140/185]	Time 0.390 (0.399)	Data 0.000 (0.004)	Loss_t 0.1524 (0.1017)	Loss_x 2.2185 (2.6271)	Acc 81.25 (46.63)	Lr 0.000100	eta 2:53:41
Epoch: [9/150][160/185]	Time 0.369 (0.398)	Data 0.000 (0.003)	Loss_t 0.0834 (0.1001)	Loss_x 2.1532 (2.5773)	Acc 76.56 (49.74)	Lr 0.000100	eta 2:53:06
Epoch: [9/150][180/185]	Time 0.406 (0.398)	Data 0.000 (0.003)	Loss_t 0.0820 (0.1009)	Loss_x 1.7093 (2.5117)	Acc 96.88 (53.42)	Lr 0.000100	eta 2:53:06
Epoch: [10/150][20/185]	Time 0.416 (0.447)	Data 0.000 (0.022)	Loss_t 0.1005 (0.0921)	Loss_x 2.4226 (2.6664)	Acc 53.12 (35.86)	Lr 0.000108	eta 3:14:16
Epoch: [10/150][40/185]	Time 0.414 (0.436)	Data 0.000 (0.011)	Loss_t 0.0778 (0.0880)	Loss_x 2.3181 (2.5980)	Acc 54.69 (40.20)	Lr 0.000108	eta 3:09:26
Epoch: [10/150][60/185]	Time 0.409 (0.426)	Data 0.000 (0.007)	Loss_t 0.0894 (0.0884)	Loss_x 2.3867 (2.5545)	Acc 53.12 (43.75)	Lr 0.000108	eta 3:04:35
Epoch: [10/150][80/185]	Time 0.404 (0.417)	Data 0.000 (0.005)	Loss_t 0.0779 (0.0865)	Loss_x 2.2206 (2.5050)	Acc 68.75 (47.68)	Lr 0.000108	eta 3:00:54
Epoch: [10/150][100/185]	Time 0.401 (0.417)	Data 0.000 (0.004)	Loss_t 0.1064 (0.0854)	Loss_x 2.3802 (2.4612)	Acc 54.69 (50.09)	Lr 0.000108	eta 3:00:29
Epoch: [10/150][120/185]	Time 0.416 (0.417)	Data 0.000 (0.004)	Loss_t 0.1236 (0.0852)	Loss_x 2.1705 (2.4243)	Acc 62.50 (52.54)	Lr 0.000108	eta 3:00:24
Epoch: [10/150][140/185]	Time 0.427 (0.418)	Data 0.000 (0.003)	Loss_t 0.0907 (0.0867)	Loss_x 2.0683 (2.3837)	Acc 70.31 (55.15)	Lr 0.000108	eta 3:00:47
Epoch: [10/150][160/185]	Time 0.432 (0.418)	Data 0.000 (0.003)	Loss_t 0.0917 (0.0862)	Loss_x 1.9058 (2.3349)	Acc 84.38 (58.08)	Lr 0.000108	eta 3:00:45
Epoch: [10/150][180/185]	Time 0.417 (0.419)	Data 0.000 (0.003)	Loss_t 0.1008 (0.0853)	Loss_x 1.8527 (2.2778)	Acc 81.25 (61.11)	Lr 0.000108	eta 3:00:41
##### Evaluating market1501 (source) #####
Extracting features from query set ...
Done, obtained 3368-by-6656 matrix
Extracting features from gallery set ...
Done, obtained 15913-by-6656 matrix
Speed: 0.0664 sec/batch
Computing distance matrix with metric=euclidean ...
Computing CMC and mAP ...
** Results **
mAP: 56.3%
CMC curve
Rank-1  : 75.1%
Rank-5  : 90.6%
Rank-10 : 94.5%
Rank-20 : 96.9%
Checkpoint saved to "log/model.pth.tar-10"
Epoch: [11/150][20/185]	Time 0.432 (0.440)	Data 0.000 (0.031)	Loss_t 0.0477 (0.0701)	Loss_x 2.3917 (2.4190)	Acc 54.69 (45.86)	Lr 0.000116	eta 3:09:43
Epoch: [11/150][40/185]	Time 0.409 (0.423)	Data 0.000 (0.016)	Loss_t 0.0971 (0.0762)	Loss_x 2.1303 (2.3597)	Acc 68.75 (50.35)	Lr 0.000116	eta 3:02:27
Epoch: [11/150][60/185]	Time 0.452 (0.424)	Data 0.000 (0.011)	Loss_t 0.1025 (0.0777)	Loss_x 2.2385 (2.3385)	Acc 67.19 (52.76)	Lr 0.000116	eta 3:02:23
Epoch: [11/150][80/185]	Time 0.440 (0.423)	Data 0.000 (0.008)	Loss_t 0.0689 (0.0790)	Loss_x 2.0707 (2.3076)	Acc 76.56 (55.33)	Lr 0.000116	eta 3:02:06
Epoch: [11/150][100/185]	Time 0.377 (0.426)	Data 0.000 (0.006)	Loss_t 0.1417 (0.0780)	Loss_x 2.3413 (2.2671)	Acc 57.81 (58.11)	Lr 0.000116	eta 3:03:03
Epoch: [11/150][120/185]	Time 0.430 (0.425)	Data 0.000 (0.005)	Loss_t 0.0583 (0.0764)	Loss_x 1.6628 (2.2198)	Acc 89.06 (60.83)	Lr 0.000116	eta 3:02:44
Epoch: [11/150][140/185]	Time 0.442 (0.427)	Data 0.000 (0.005)	Loss_t 0.1158 (0.0756)	Loss_x 1.7436 (2.1693)	Acc 92.19 (63.74)	Lr 0.000116	eta 3:03:30
Epoch: [11/150][160/185]	Time 0.422 (0.429)	Data 0.000 (0.004)	Loss_t 0.0952 (0.0749)	Loss_x 1.7044 (2.1232)	Acc 85.94 (66.31)	Lr 0.000116	eta 3:03:54
Epoch: [11/150][180/185]	Time 0.355 (0.425)	Data 0.000 (0.004)	Loss_t 0.0673 (0.0741)	Loss_x 1.4964 (2.0697)	Acc 95.31 (69.06)	Lr 0.000116	eta 3:02:14
